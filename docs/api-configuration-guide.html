<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <title>API Configuration Guide - AI Chat Studio v2.0.0</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            background-color: #f5f5f5;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }

        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 40px 20px;
            text-align: center;
            margin-bottom: 30px;
            border-radius: 10px;
        }

        .header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
        }

        .header p {
            font-size: 1.2em;
            opacity: 0.9;
        }

        .content {
            background: white;
            padding: 40px;
            border-radius: 10px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            margin-bottom: 30px;
        }

        .section {
            margin-bottom: 40px;
        }

        .section h2 {
            color: #667eea;
            font-size: 1.8em;
            margin-bottom: 20px;
            border-bottom: 2px solid #667eea;
            padding-bottom: 10px;
        }

        .section h3 {
            color: #333;
            font-size: 1.4em;
            margin-bottom: 15px;
            margin-top: 25px;
        }

        .section h4 {
            color: #555;
            font-size: 1.2em;
            margin-bottom: 10px;
            margin-top: 20px;
        }

        .section p {
            margin-bottom: 15px;
            text-align: justify;
        }

        .section ul, .section ol {
            margin-bottom: 15px;
            padding-left: 30px;
        }

        .section li {
            margin-bottom: 8px;
        }

        .code-block {
            background: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 5px;
            padding: 15px;
            margin: 15px 0;
            overflow-x: auto;
            font-family: 'Courier New', monospace;
            font-size: 14px;
        }

        .code-block code {
            background: none;
            padding: 0;
            color: #d63384;
        }

        .warning {
            background: #fff3cd;
            border: 1px solid #ffeaa7;
            border-radius: 5px;
            padding: 15px;
            margin: 15px 0;
            border-left: 4px solid #f39c12;
        }

        .warning strong {
            color: #856404;
        }

        .info {
            background: #d1ecf1;
            border: 1px solid #bee5eb;
            border-radius: 5px;
            padding: 15px;
            margin: 15px 0;
            border-left: 4px solid #17a2b8;
        }

        .info strong {
            color: #0c5460;
        }

        .success {
            background: #d4edda;
            border: 1px solid #c3e6cb;
            border-radius: 5px;
            padding: 15px;
            margin: 15px 0;
            border-left: 4px solid #28a745;
        }

        .success strong {
            color: #155724;
        }

        .grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }

        .card {
            background: white;
            border: 1px solid #e9ecef;
            border-radius: 8px;
            padding: 20px;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
        }

        .card h4 {
            color: #667eea;
            margin-top: 0;
            margin-bottom: 15px;
        }

        .nav {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 30px;
        }

        .nav h3 {
            margin-bottom: 15px;
            color: #667eea;
        }

        .nav a {
            display: block;
            color: #495057;
            text-decoration: none;
            padding: 8px 0;
            border-bottom: 1px solid #e9ecef;
        }

        .nav a:hover {
            color: #667eea;
        }

        .nav a:last-child {
            border-bottom: none;
        }

        .table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }

        .table th, .table td {
            border: 1px solid #e9ecef;
            padding: 12px;
            text-align: left;
        }

        .table th {
            background: #f8f9fa;
            font-weight: 600;
            color: #495057;
        }

        .table tr:nth-child(even) {
            background: #f8f9fa;
        }

        .provider-logo {
            font-weight: bold;
            font-size: 1.1em;
            margin-bottom: 10px;
        }

        .openai { color: #412991; }
        .anthropic { color: #D97757; }
        .google { color: #4285F4; }
        .ollama { color: #00D8FF; }
        .lmstudio { color: #FF6B35; }

        .highlight {
            background: #fff3cd;
            padding: 2px 6px;
            border-radius: 3px;
            font-weight: 500;
        }

        .feature-list {
            background: #f8f9fa;
            border-radius: 8px;
            padding: 20px;
            margin: 15px 0;
        }

        .feature-list h4 {
            margin-top: 0;
            color: #667eea;
        }

        .feature-list ul {
            margin-bottom: 0;
        }

        /* Font Awesome Icon Styles */
        .fa-icon {
            font-family: 'Font Awesome 5 Free';
            font-weight: 900;
            font-size: 1.1em;
            margin-right: 8px;
        }

        .fa-check-circle::before { content: "\f058"; color: #28a745; }

        @media (max-width: 768px) {
            .container {
                padding: 10px;
            }

            .content {
                padding: 20px;
            }

            .header h1 {
                font-size: 2em;
            }

            .grid {
                grid-template-columns: 1fr;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>API Configuration Guide</h1>
            <p>Configure AI providers and API settings for AI Chat Studio v2.0.0</p>
        </div>

        <div class="nav">
            <h3>Table of Contents</h3>
            <a href="#overview">Overview</a>
            <a href="#supported-providers">Supported Providers</a>
            <a href="#openai-setup">OpenAI Setup</a>
            <a href="#anthropic-setup">Anthropic Claude Setup</a>
            <a href="#google-setup">Google Gemini Setup</a>
            <a href="#local-providers">Local Providers</a>
            <a href="#environment-variables">Environment Variables</a>
            <a href="#advanced-config">Advanced Configuration</a>
            <a href="#testing-validation">Testing & Validation</a>
            <a href="#troubleshooting">Troubleshooting</a>
        </div>

        <div class="content">
            <div class="section" id="overview">
                <h2>Overview</h2>
                <p>AI Chat Studio v2.0.0 supports multiple AI providers, allowing you to choose the best model for your needs. This guide covers configuration for all supported providers, from cloud services to local installations.</p>
                
                <div class="info">
                    <strong>Key Benefits of Multi-Provider Support:</strong>
                    <ul>
                        <li>Compare responses across different AI models</li>
                        <li>Use cost-effective models for simple tasks</li>
                        <li>Access specialized models for specific use cases</li>
                        <li>Maintain availability with fallback options</li>
                        <li>Optimize performance and costs</li>
                    </ul>
                </div>

                <h3>Configuration Methods</h3>
                <div class="grid">
                    <div class="card">
                        <h4>GUI Configuration</h4>
                        <p>Use the built-in settings interface to configure providers visually. Recommended for beginners.</p>
                    </div>
                    <div class="card">
                        <h4>Environment Variables</h4>
                        <p>Set API keys and settings via environment variables. Best for production deployments.</p>
                    </div>
                    <div class="card">
                        <h4>Configuration Files</h4>
                        <p>Edit JSON or PHP configuration files directly. Ideal for advanced users and bulk configurations.</p>
                    </div>
                    <div class="card">
                        <h4>Runtime Configuration</h4>
                        <p>Configure providers programmatically through the API. Perfect for automated deployments.</p>
                    </div>
                </div>
            </div>

            <div class="section" id="supported-providers">
                <h2>Supported AI Providers</h2>
                
                <div class="table">
                    <table>
                        <thead>
                            <tr>
                                <th>Provider</th>
                                <th>Models</th>
                                <th>Cost</th>
                                <th>Setup Difficulty</th>
                                <th>Best For</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><span class="provider-logo openai">OpenAI</span></td>
                                <td>GPT-3.5, GPT-4, GPT-4o</td>
                                <td>Pay-per-use</td>
                                <td>Easy</td>
                                <td>General purpose, research</td>
                            </tr>
                            <tr>
                                <td><span class="provider-logo anthropic">Anthropic</span></td>
                                <td>Claude 3 Haiku, Sonnet, Opus</td>
                                <td>Pay-per-use</td>
                                <td>Easy</td>
                                <td>Safety-focused conversations</td>
                            </tr>
                            <tr>
                                <td><span class="provider-logo google">Google</span></td>
                                <td>Gemini Pro, Gemini Ultra</td>
                                <td>Freemium</td>
                                <td>Moderate</td>
                                <td>Large context, multimodal</td>
                            </tr>
                            <tr>
                                <td><span class="provider-logo ollama">Ollama</span></td>
                                <td>Llama, Mistral, CodeLlama</td>
                                <td>Free (local)</td>
                                <td>Moderate</td>
                                <td>Privacy, offline use</td>
                            </tr>
                            <tr>
                                <td><span class="provider-logo lmstudio">LM Studio</span></td>
                                <td>Various GGUF models</td>
                                <td>Free (local)</td>
                                <td>Easy</td>
                                <td>Easy local setup</td>
                            </tr>
                        </tbody>
                    </table>
                </div>

                <div class="warning">
                    <strong>Cost Consideration:</strong> Cloud providers charge per token or request. Monitor your usage and set limits to avoid unexpected charges.
                </div>
            </div>

            <div class="section" id="openai-setup">
                <h2><span class="provider-logo openai">OpenAI</span> Setup</h2>
                
                <h3>Step 1: Get Your API Key</h3>
                <ol>
                    <li>Visit <a href="https://platform.openai.com/api-keys" target="_blank">OpenAI API Keys</a></li>
                    <li>Sign in to your OpenAI account (create one if needed)</li>
                    <li>Click "Create new secret key"</li>
                    <li>Copy the key immediately (you won't see it again)</li>
                    <li>Add billing information to your OpenAI account</li>
                </ol>

                <h3>Step 2: Configure in AI Chat Studio</h3>
                
                <h4>Method A: GUI Configuration</h4>
                <ol>
                    <li>Open AI Chat Studio in your browser</li>
                    <li>Navigate to Settings/Configuration</li>
                    <li>Select "OpenAI" as provider</li>
                    <li>Enter your API key</li>
                    <li>Choose your preferred model:
                        <ul>
                            <li><code>gpt-3.5-turbo</code> - Fast and cost-effective</li>
                            <li><code>gpt-4</code> - More capable, higher cost</li>
                            <li><code>gpt-4o</code> - Latest model with vision capabilities</li>
                        </ul>
                    </li>
                    <li>Save settings</li>
                </ol>

                <h4>Method B: Environment Variables</h4>
                <div class="code-block">
                    <code># Add to your environment or .env file
OPENAI_API_KEY=sk-your-api-key-here
OPENAI_MODEL=gpt-3.5-turbo
OPENAI_MAX_TOKENS=2048
OPENAI_TEMPERATURE=0.7
</code>
                </div>

                <h4>Method C: Configuration File</h4>
                <div class="code-block">
                    <code>{
  "providers": {
    "openai": {
      "api_key": "sk-your-api-key-here",
      "model": "gpt-3.5-turbo",
      "max_tokens": 2048,
      "temperature": 0.7,
      "enabled": true
    }
  }
}
</code>
                </div>

                <div class="feature-list">
                    <h4>Available OpenAI Models</h4>
                    <ul>
                        <li><strong>gpt-3.5-turbo:</strong> Fast, economical, good for most tasks</li>
                        <li><strong>gpt-4:</strong> More capable, better reasoning, higher cost</li>
                        <li><strong>gpt-4o:</strong> Latest multimodal model, supports images</li>
                        <li><strong>gpt-4-turbo:</strong> Optimized version of GPT-4</li>
                    </ul>
                </div>

                <div class="warning">
                    <strong>API Key Security:</strong> Never commit API keys to version control. Use environment variables in production.
                </div>
            </div>

            <div class="section" id="anthropic-setup">
                <h2><span class="provider-logo anthropic">Anthropic Claude</span> Setup</h2>
                
                <h3>Step 1: Get Your API Key</h3>
                <ol>
                    <li>Visit <a href="https://console.anthropic.com/" target="_blank">Anthropic Console</a></li>
                    <li>Sign up or log in to your account</li>
                    <li>Navigate to API Keys section</li>
                    <li>Create a new API key</li>
                    <li>Copy and securely store the key</li>
                </ol>

                <h3>Step 2: Configure in AI Chat Studio</h3>
                
                <h4>Method A: GUI Configuration</h4>
                <ol>
                    <li>Open settings in AI Chat Studio</li>
                    <li>Select "Anthropic" as provider</li>
                    <li>Enter your API key</li>
                    <li>Choose model:
                        <ul>
                            <li><code>claude-3-haiku-20240307</code> - Fast and economical</li>
                            <li><code>claude-3-sonnet-20240229</code> - Balanced performance</li>
                            <li><code>claude-3-opus-20240229</code> - Most capable</li>
                        </ul>
                    </li>
                    <li>Set maximum tokens (default: 1024)</li>
                    <li>Save configuration</li>
                </ol>

                <h4>Method B: Environment Variables</h4>
                <div class="code-block">
                    <code># Add to your environment or .env file
ANTHROPIC_API_KEY=sk-ant-your-api-key-here
ANTHROPIC_MODEL=claude-3-sonnet-20240229
ANTHROPIC_MAX_TOKENS=1024
ANTHROPIC_TEMPERATURE=0.7
</code>
                </div>

                <h3>Anthropic Claude Models Comparison</h3>
                <div class="table">
                    <table>
                        <thead>
                            <tr>
                                <th>Model</th>
                                <th>Speed</th>
                                <th>Capability</th>
                                <th>Cost</th>
                                <th>Best For</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>Claude 3 Haiku</td>
                                <td>Very Fast</td>
                                <td>Good</td>
                                <td>Low</td>
                                <td>Simple tasks, high volume</td>
                            </tr>
                            <tr>
                                <td>Claude 3 Sonnet</td>
                                <td>Fast</td>
                                <td>Very Good</td>
                                <td>Medium</td>
                                <td>General conversations</td>
                            </tr>
                            <tr>
                                <td>Claude 3 Opus</td>
                                <td>Moderate</td>
                                <td>Excellent</td>
                                <td>High</td>
                                <td>Complex reasoning</td>
                            </tr>
                        </tbody>
                    </table>
                </div>

                <div class="success">
                    <strong>Claude Advantage:</strong> Claude is designed to be helpful, harmless, and honest, making it excellent for sensitive conversations.
                </div>
            </div>

            <div class="section" id="google-setup">
                <h2><span class="provider-logo google">Google Gemini</span> Setup</h2>
                
                <h3>Step 1: Get Your API Key</h3>
                <ol>
                    <li>Visit <a href="https://aistudio.google.com/" target="_blank">Google AI Studio</a></li>
                    <li>Sign in with your Google account</li>
                    <li>Click "Create API Key"</li>
                    <li>Copy the generated API key</li>
                    <li>Note: Free tier includes generous usage limits</li>
                </ol>

                <h3>Step 2: Configure in AI Chat Studio</h3>
                
                <h4>Method A: GUI Configuration</h4>
                <ol>
                    <li>Open AI Chat Studio settings</li>
                    <li>Select "Google Gemini" as provider</li>
                    <li>Enter your API key</li>
                    <li>Choose model:
                        <ul>
                            <li><code>gemini-pro</code> - Standard model</li>
                            <li><code>gemini-pro-vision</code> - Supports images</li>
                        </ul>
                    </li>
                    <li>Configure safety settings if needed</li>
                    <li>Save settings</li>
                </ol>

                <h4>Method B: Environment Variables</h4>
                <div class="code-block">
                    <code># Add to your environment or .env file
GOOGLE_API_KEY=your-google-api-key-here
GOOGLE_MODEL=gemini-pro
GOOGLE_MAX_TOKENS=2048
GOOGLE_TEMPERATURE=0.7
</code>
                </div>

                <div class="feature-list">
                    <h4>Google Gemini Features</h4>
                    <ul>
                        <li><strong>Multimodal:</strong> Process text and images</li>
                        <li><strong>Large Context:</strong> Handle extensive conversations</li>
                        <li><strong>Code Generation:</strong> Strong programming capabilities</li>
                        <li><strong>Free Tier:</strong> Generous usage limits for testing</li>
                    </ul>
                </div>
            </div>

            <div class="section" id="local-providers">
                <h2>Local AI Providers</h2>
                
                <p>For privacy-conscious users or those without internet access, local AI providers offer excellent alternatives.</p>

                <h3><span class="provider-logo ollama">Ollama</span> Setup</h3>
                
                <h4>Installation</h4>
                <div class="code-block">
                    <code># Windows/Mac
# Download from https://ollama.ai

# Linux
curl -fsSL https://ollama.ai/install.sh | sh

# Verify installation
ollama --version
</code>
                </div>

                <h4>Download Models</h4>
                <div class="code-block">
                    <code># List available models
ollama list

# Download a model (e.g., Llama 2)
ollama pull llama2

# Or try other models
ollama pull mistral
ollama pull codellama
ollama pull phi
</code>
                </div>

                <h4>Configuration</h4>
                <div class="code-block">
                    <code># Configure AI Chat Studio
Provider: Ollama
Endpoint: http://localhost:11434
Model: llama2
</code>
                </div>

                <h3><span class="provider-logo lmstudio">LM Studio</span> Setup</h3>
                
                <h4>Installation & Setup</h4>
                <ol>
                    <li>Download <a href="https://lmstudio.ai/" target="_blank">LM Studio</a></li>
                    <li>Install and launch the application</li>
                    <li>Browse and download GGUF models</li>
                    <li>Start the local server:
                        <ul>
                            <li>Go to "Local Server" tab</li>
                            <li>Click "Start Server"</li>
                            <li>Note the port (default: 1234)</li>
                        </ul>
                    </li>
                </ol>

                <h4>Configuration</h4>
                <div class="code-block">
                    <code># Configure AI Chat Studio
Provider: LM Studio
Endpoint: http://localhost:1234
Model: (select your loaded model)
</code>
                </div>

                <div class="success">
                    <strong>Local Provider Benefits:</strong> Complete privacy, no API costs, offline capability, and full control over your data.
                </div>

                <div class="warning">
                    <strong>Resource Requirements:</strong> Local models require significant RAM and GPU resources. Start with smaller models if your system is limited.
                </div>
            </div>

            <div class="section" id="environment-variables">
                <h2>Environment Variables Configuration</h2>
                
                <p>Environment variables are the recommended way to store sensitive configuration data in production environments.</p>

                <h3>Supported Environment Variables</h3>
                
                <h4>OpenAI</h4>
                <div class="code-block">
                    <code>OPENAI_API_KEY=sk-your-openai-key-here
OPENAI_MODEL=gpt-3.5-turbo
OPENAI_MAX_TOKENS=2048
OPENAI_TEMPERATURE=0.7
OPENAI_TOP_P=1.0
OPENAI_FREQUENCY_PENALTY=0.0
OPENAI_PRESENCE_PENALTY=0.0
</code>
                </div>

                <h4>Anthropic</h4>
                <div class="code-block">
                    <code>ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here
ANTHROPIC_MODEL=claude-3-sonnet-20240229
ANTHROPIC_MAX_TOKENS=1024
ANTHROPIC_TEMPERATURE=0.7
ANTHROPIC_TOP_P=0.9
</code>
                </div>

                <h4>Google Gemini</h4>
                <div class="code-block">
                    <code>GOOGLE_API_KEY=your-google-api-key-here
GOOGLE_MODEL=gemini-pro
GOOGLE_MAX_TOKENS=2048
GOOGLE_TEMPERATURE=0.7
GOOGLE_TOP_P=0.8
</code>
                </div>

                <h4>Local Providers</h4>
                <div class="code-block">
                    <code># Ollama
OLLAMA_ENDPOINT=http://localhost:11434
OLLAMA_MODEL=llama2

# LM Studio
LM_STUDIO_ENDPOINT=http://localhost:1234
LM_STUDIO_MODEL=your-loaded-model
</code>
                </div>

                <h3>Setting Environment Variables</h3>
                
                <h4>Linux/macOS (Bash)</h4>
                <div class="code-block">
                    <code># Add to ~/.bashrc or ~/.zshrc
export OPENAI_API_KEY="sk-your-key-here"
export ANTHROPIC_API_KEY="sk-ant-your-key-here"

# Reload configuration
source ~/.bashrc
</code>
                </div>

                <h4>Windows (Command Prompt)</h4>
                <div class="code-block">
                    <code># Set temporarily for current session
set OPENAI_API_KEY=sk-your-key-here
set ANTHROPIC_API_KEY=sk-ant-your-key-here

# Set permanently
setx OPENAI_API_KEY "sk-your-key-here"
setx ANTHROPIC_API_KEY "sk-ant-your-key-here"
</code>
                </div>

                <h4>PHP/.env File</h4>
                <div class="code-block">
                    <code># Create .env file in your project root
OPENAI_API_KEY=sk-your-key-here
ANTHROPIC_API_KEY=sk-ant-your-key-here
GOOGLE_API_KEY=your-google-key-here

# Load in your PHP application
if (file_exists('.env')) {
    $lines = file('.env', FILE_IGNORE_NEW_LINES | FILE_SKIP_EMPTY_LINES);
    foreach ($lines as $line) {
        if (strpos(trim($line), '#') === 0) continue;
        list($name, $value) = explode('=', $line, 2);
        $_ENV[trim($name)] = trim($value);
        putenv(trim($name) . '=' . trim($value));
    }
}
</code>
                </div>
            </div>

            <div class="section" id="advanced-config">
                <h2>Advanced Configuration</h2>
                
                <h3>Multi-Provider Setup</h3>
                <p>Configure multiple providers for comparison or fallback purposes:</p>
                
                <div class="code-block">
                    <code>{
  "providers": {
    "openai": {
      "api_key": "sk-your-openai-key",
      "model": "gpt-3.5-turbo",
      "enabled": true,
      "priority": 1
    },
    "anthropic": {
      "api_key": "sk-ant-your-anthropic-key",
      "model": "claude-3-sonnet-20240229",
      "enabled": true,
      "priority": 2
    },
    "google": {
      "api_key": "your-google-key",
      "model": "gemini-pro",
      "enabled": false,
      "priority": 3
    }
  },
  "settings": {
    "default_provider": "openai",
    "fallback_enabled": true,
    "max_retries": 3,
    "request_timeout": 30
  }
}
</code>
                </div>

                <h3>Rate Limiting Configuration</h3>
                <div class="code-block">
                    <code>{
  "rate_limiting": {
    "requests_per_minute": 60,
    "requests_per_hour": 1000,
    "requests_per_day": 10000,
    "burst_limit": 10
  },
  "cost_management": {
    "daily_budget_limit": 10.00,
    "monthly_budget_limit": 100.00,
    "alert_thresholds": [50, 80, 95]
  }
}
</code>
                </div>

                <h3>Model-Specific Parameters</h3>
                <div class="table">
                    <table>
                        <thead>
                            <tr>
                                <th>Parameter</th>
                                <th>Description</th>
                                <th>Range</th>
                                <th>Default</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>max_tokens</td>
                                <td>Maximum response length</td>
                                <td>1-4096</td>
                                <td>1024</td>
                            </tr>
                            <tr>
                                <td>temperature</td>
                                <td>Response creativity</td>
                                <td>0.0-2.0</td>
                                <td>0.7</td>
                            </tr>
                            <tr>
                                <td>top_p</td>
                                <td>Nucleus sampling</td>
                                <td>0.0-1.0</td>
                                <td>1.0</td>
                            </tr>
                            <tr>
                                <td>frequency_penalty</td>
                                <td>Reduces repetition</td>
                                <td>-2.0-2.0</td>
                                <td>0.0</td>
                            </tr>
                            <tr>
                                <td>presence_penalty</td>
                                <td>Encourages new topics</td>
                                <td>-2.0-2.0</td>
                                <td>0.0</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </div>

            <div class="section" id="testing-validation">
                <h2>Testing & Validation</h2>
                
                <h3>Connection Testing</h3>
                
                <h4>Test API Connectivity</h4>
                <div class="code-block">
                    <code># Test OpenAI connection
curl -H "Authorization: Bearer sk-your-openai-key" \
     https://api.openai.com/v1/models

# Test Anthropic connection
curl https://api.anthropic.com/v1/messages \
  -H "Content-Type: application/json" \
  -H "X-API-Key: sk-ant-your-key" \
  -d '{"model":"claude-3-sonnet-20240229","max_tokens":1024,"messages":[{"role":"user","content":"Hello"}]}'

# Test Google Gemini
curl https://generativelanguage.googleapis.com/v1/models \
  -H "x-goog-api-key: your-google-key"
</code>
                </div>

                <h3>Validation Checklist</h3>
                
                <div class="success">
                    <strong>Pre-Production Checklist:</strong>
                    <ul>
                        <li><i class="fa-icon fa-check-circle"></i> API keys are valid and have sufficient credits</li>
                        <li><i class="fa-icon fa-check-circle"></i> Models are accessible and responding</li>
                        <li><i class="fa-icon fa-check-circle"></i> Error handling is working correctly</li>
                        <li><i class="fa-icon fa-check-circle"></i> Rate limiting is configured appropriately</li>
                        <li><i class="fa-icon fa-check-circle"></i> Cost monitoring is in place</li>
                        <li><i class="fa-icon fa-check-circle"></i> Security headers are set</li>
                        <li><i class="fa-icon fa-check-circle"></i> HTTPS is enabled for production</li>
                        <li><i class="fa-icon fa-check-circle"></i> Environment variables are properly secured</li>
                    </ul>
                </div>

                <h3>Monitoring & Analytics</h3>
                <p>Set up monitoring to track API usage and costs:</p>
                
                <div class="code-block">
                    <code># Example monitoring configuration
{
  "monitoring": {
    "log_requests": true,
    "track_costs": true,
    "alert_on_errors": true,
    "performance_metrics": true,
    "daily_reports": true,
    "weekly_summaries": true
  },
  "alerts": {
    "high_error_rate": 5,
    "unusual_spending": 50,
    "api_quota_exceeded": 90
  }
}
</code>
                </div>
            </div>

            <div class="section" id="troubleshooting">
                <h2>Troubleshooting</h2>
                
                <h3>Common API Configuration Issues</h3>
                
                <h4>Issue: "Invalid API Key" Error</h4>
                <div class="warning">
                    <strong>Solutions:</strong>
                    <ul>
                        <li>Verify the API key is copied correctly (no extra spaces)</li>
                        <li>Check if the key has sufficient permissions</li>
                        <li>Ensure the API key hasn't expired</li>
                        <li>Confirm the API key format matches the provider requirements</li>
                        <li>Test the key directly with curl or Postman</li>
                    </ul>
                </div>

                <h4>Issue: "Model Not Found" Error</h4>
                <div class="warning">
                    <strong>Solutions:</strong>
                    <ul>
                        <li>Verify the model name is spelled correctly</li>
                        <li>Check if the model is available in your region</li>
                        <li>Ensure your API plan includes access to the model</li>
                        <li>Update to the latest available model version</li>
                        <li>Check provider's model availability documentation</li>
                    </ul>
                </div>

                <h4>Issue: "Rate Limit Exceeded"</h4>
                <div class="warning">
                    <strong>Solutions:</strong>
                    <ul>
                        <li>Implement exponential backoff retry logic</li>
                        <li>Reduce request frequency</li>
                        <li>Upgrade to a higher API tier if available</li>
                        <li>Use multiple API keys if allowed</li>
                        <li>Implement request queuing</li>
                    </ul>
                </div>

                <h4>Issue: "Connection Timeout"</h4>
                <div class="warning">
                    <strong>Solutions:</strong>
                    <ul>
                        <li>Increase timeout values in configuration</li>
                        <li>Check network connectivity</li>
                        <li>Verify firewall settings</li>
                        <li>Test with simpler, shorter prompts</li>
                        <li>Monitor API provider status pages</li>
                    </ul>
                </div>

                <h3>Debug Configuration</h3>
                <div class="code-block">
                    <code># Enable debug logging
define('DEBUG_API_CALLS', true);
define('LOG_LEVEL', 'DEBUG');

// Log API requests and responses
function debug_api_call($provider, $request, $response) {
    if (DEBUG_API_CALLS) {
        error_log("API Call - Provider: $provider");
        error_log("Request: " . json_encode($request));
        error_log("Response: " . json_encode($response));
    }
}
</code>
                </div>

                <div class="info">
                    <strong>Need More Help?</strong> Check the provider's official documentation or visit the GitHub issues page for AI Chat Studio.
                </div>
            </div>
        </div>
    </div>
</body>
</html>